{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 11912806,
     "sourceType": "datasetVersion",
     "datasetId": 7484236,
     "isSourceIdPinned": true
    },
    {
     "sourceId": 11930419,
     "sourceType": "datasetVersion",
     "datasetId": 7398577,
     "isSourceIdPinned": true
    }
   ],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Introduction\nThis notebook evaluates the T5-small model's performance on question answering tasks \nWe analyze:\n- Zero-shot capabilities\n- Few-shot learning\n- Context vs no-context comparisons\n- Fine-tuned performance ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Dataset Loading and Utility Functions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nfinetuning_data=pd.read_parquet(\"/kaggle/input/nlp-resources/tuning_data.parquet\")\nhyperparameter_tuning_data=pd.read_parquet(\"/kaggle/input/nlp-resources/hyperparameter_tuning_data.parquet\")\ntest_data=pd.read_parquet(\"/kaggle/input/nlp-resources/test_data.parquet\")\ncontexts=pd.concat([test_data[\"context\"],hyperparameter_tuning_data[\"context\"],finetuning_data[\"context\"]]).to_list()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T07:53:11.493304Z",
     "iopub.execute_input": "2025-05-24T07:53:11.494330Z",
     "iopub.status.idle": "2025-05-24T07:53:12.182921Z",
     "shell.execute_reply.started": "2025-05-24T07:53:11.494298Z",
     "shell.execute_reply": "2025-05-24T07:53:12.182210Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import TrainerCallback\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess(example,tokenizer,max_length_input=512,max_length_labels=64,no_context=False):\n",
    "    input_text = f\"question: {example['question']}\" \n",
    "    if (not no_context):\n",
    "        input_text+=f\" context: {example['context']}\"\n",
    "    target_text = example[\"answer\"]\n",
    "    inputs = tokenizer(input_text, max_length=max_length_input, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(target_text, max_length=max_length_labels, truncation=True, padding=\"max_length\")[\"input_ids\"] \n",
    "    inputs[\"labels\"] =labels\n",
    "    return inputs\n",
    "\n",
    "def generate_answer(model, tokenizer, question, device, max_input_length=512, max_output_length=64, context=None):\n",
    "    model.eval()\n",
    "    input_text = f\"question: {question}\"\n",
    "    if(context):\n",
    "        input_text+= f\" context: {context}\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_output_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3\n",
    "        \n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def remove_punc(text):\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    gt_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gt_tokens)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "def bleu_score(prediction, ground_truth):\n",
    "    smoothie = SmoothingFunction().method4  # migliora BLEU su frasi corte\n",
    "    pred_tokens = nltk.word_tokenize(prediction.lower())\n",
    "    gt_tokens = nltk.word_tokenize(ground_truth.lower())\n",
    "    return sentence_bleu([gt_tokens], pred_tokens, smoothing_function=smoothie)\n",
    "    \n",
    "def get_top_k_contexts(context_embeddings,model_embed,query,k=3):\n",
    "    query_emb=model_embed.encode([query], convert_to_numpy=True)\n",
    "    similarity=cosine_similarity(query_emb,context_embeddings)[0]\n",
    "    #print(similarity)\n",
    "    top_k_idx = similarity.argsort()[-k:]\n",
    "    return [contexts[i] for i in top_k_idx]\n",
    "    \n",
    "def eval_answers(model,tokenizer,test_data=test_data,max_input=512,max_output=64, rag=False, no_context=False):\n",
    "    exact_matches = []\n",
    "    f1_scores = []\n",
    "    bleu_scores=[]\n",
    "    for idx, row in test_data.iterrows():\n",
    "        context= None if no_context else row['context']\n",
    "        pred_answer = generate_answer(model, tokenizer, row['question'],max_input_length=max_input,max_output_length=max_output, device=device,context=context )\n",
    "        em = exact_match_score(pred_answer, row['answer'])\n",
    "        f1 = f1_score(pred_answer, row['answer'])\n",
    "        bleu = bleu_score(pred_answer, row['answer'])\n",
    "        exact_matches.append(em)\n",
    "        f1_scores.append(f1)\n",
    "        bleu_scores.append(bleu)\n",
    "    return sum(bleu_scores) / len(bleu_scores) * 100,sum(exact_matches) / len(exact_matches) * 100, sum(f1_scores) / len(f1_scores) * 100\n",
    "def print_scores(avg_bleu=-1, avg_em=-1, avg_f1=-1,model_name=\"\",scores_path=\"/kaggle/input/nlp-resources/scores_t5_rag.parquet\",use_backup=False):\n",
    "    \n",
    "    if(use_backup):\n",
    "        scores=pd.read_parquet(scores_path)\n",
    "        scores_array=scores[scores[\"model_name\"]==model_name][[\"avg_bleu\",\"avg_em\",\"avg_f1\"]].values[0]\n",
    "    else:\n",
    "        scores_array=np.array([avg_bleu, avg_em, avg_f1])\n",
    "    print(f\"Scores of {model_name} model :\")\n",
    "    print(f\"Average BLEU score: {scores_array[0]:.2f}\")\n",
    "    print(f\"Exact Match: {scores_array[1]:.2f}%\")\n",
    "    print(f\"F1 Score: {scores_array[2]:.2f}%\")\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:09.501304Z",
     "iopub.execute_input": "2025-05-24T00:29:09.501678Z",
     "iopub.status.idle": "2025-05-24T00:29:36.630273Z",
     "shell.execute_reply.started": "2025-05-24T00:29:09.501655Z",
     "shell.execute_reply": "2025-05-24T00:29:36.629504Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2025-05-24 00:29:23.378200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748046563.547707      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748046563.602669      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Evaluation Metrics\n\nWe use three key metrics:\n\n| **Metric**       | **Description**         | **Importance**                |\n|------------------|-------------------------|-------------------------------|\n| Exact Match (EM) | Strict string matching  | Measures precision            |\n| F1 Score         | Token-level overlap     | Balances precision/recall     |\n| BLEU Score       | N-gram similarity       | Evaluates fluency             |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "\n## 3. Zero-Shot Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n\ntokenizer_T5 = T5Tokenizer.from_pretrained(\"t5-small\")\nmodel_T5_pretrained = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_T5_pretrained.to(device)\nmodel_T5_pretrained.eval()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:36.632160Z",
     "iopub.execute_input": "2025-05-24T00:29:36.632683Z",
     "iopub.status.idle": "2025-05-24T00:29:45.205939Z",
     "shell.execute_reply.started": "2025-05-24T00:29:36.632664Z",
     "shell.execute_reply": "2025-05-24T00:29:45.205340Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba3314948f134ac7b1c0a1ef93ffd609"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "346c52932dc44ac084be7804a6af7408"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d18a948d870849bdb28ef62313f935e6"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcd17c7988a2422896fa46e6e74d2198"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a008663d6aca4baa879957f95519ba70"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d84ee91a18504167878638b4782f45b9"
      }
     },
     "metadata": {}
    },
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "#### Zero shot sample :",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sample_zero_shot=test_data.sample(n=1,random_state=42)\nprint(f\"Sampled exapmle:\\n#Question: {sample_zero_shot['question'].values[0]}\\n#Context:{sample_zero_shot['context'].values[0]}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:45.206644Z",
     "iopub.execute_input": "2025-05-24T00:29:45.206879Z",
     "iopub.status.idle": "2025-05-24T00:29:45.215563Z",
     "shell.execute_reply.started": "2025-05-24T00:29:45.206860Z",
     "shell.execute_reply": "2025-05-24T00:29:45.214895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Sampled exapmle:\n#Question: What are the responsibilities and requirements for the Software Architect position at the entertainment company?\n#Context:an entertainment company specializing in advice-based products and services is looking for a software architect to work alongside their growing team, as a contractor. responsibilities and requirements -develop and analyze the design and architecture of complex software application systems. -provide architectural and implementation oversight and guidance to ensure consistency and quality of design and code. -analyze and document existing systems, review preexisting complex code and provide recommendations to improve performance & maintainability. -ability to communicate technical issues and concepts clearly, both orally and in writing -write test and debug complex problems in various modules of the various software application -code reviews -manage test and acceptance activities -direct contribution to development and test efforts -manage and support system deployment- -design and build reusable modules to be used throughout our applications -collaborate with senior developers to design and create the next generation of our software, services and systems architecture. -write application code using latest c# and asp.net framework -assist in building database structure for sql server to meet software data storage needs -understand cloud engineering, data streaming, high availability systems, high performance computing and grid computing. -ability to handle and prioritize multiple tasks while managing day to day transactions -self-motivated team player with the ability to work independently -strong analytical and problem solving skills -attention to detail and accuracy -communication skills and ability to work collaboratively with other departments -ability to gracefully shift priorities and be able to handle change -committed to company mission and customer’s needs -transfers thoughts and expresses ideas effectively individually or in a group setting -demonstrates a high level of dependability in doing their job and being there for his/her team -develops cooperation and teamwork and works towards solutions that general benefit all parties involved -very good communication skills, self-motivated, “go getter” kind of person required -10+ years of professional web development experience using c#, .net, asp.net 3.5 – 4.0, mvc, and wcf -10+ years design and development experience of enterprise applications using common development and execution platforms (e.g. j2ee, .net) -7+ year’s professional experience with sql server 2012 and up as well as transact-sql. solid understanding of stored procedures, triggers, database design and relational design -hands-on experience with html5, css3, javascript. -experience with time sensitive & highly optimized rest api & windows services -understanding of xml/web services -knowledge in technological approach as well as in product feature -bachelor’s degree or equivalent in a relevant discipline. -experience with agile software development (specifically scrum) -experience with test driven development (tdd) -experience with cloud ivr, live video chat, chat and texting web integration.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": "#### Zero shot generated output :",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "zero_shot_answer=generate_answer(model_T5_pretrained, tokenizer_T5, question=sample_zero_shot['question'].values[0], device=device, max_input_length=512, max_output_length=128, context=sample_zero_shot['context'].values[0])\nprint(f\"Genereated answer:{zero_shot_answer}\\n\\nDataset Answer:{sample_zero_shot['answer'].values[0]}\")\nprint(f\"\\nComparison with dataset answer:\\nF1:{f1_score(zero_shot_answer, sample_zero_shot['answer'].values[0]):.2f}\",f\"BLEU:{bleu_score(zero_shot_answer, sample_zero_shot['answer'].values[0]):.2f}\",f\"EM:{exact_match_score(zero_shot_answer, sample_zero_shot['answer'].values[0]):.2f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:45.216320Z",
     "iopub.execute_input": "2025-05-24T00:29:45.216561Z",
     "iopub.status.idle": "2025-05-24T00:29:46.495338Z",
     "shell.execute_reply.started": "2025-05-24T00:29:45.216544Z",
     "shell.execute_reply": "2025-05-24T00:29:46.494523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Genereated answer:develop and analyze the design and architecture of complex software applications\n\nDataset Answer:The responsibilities and requirements for the Software Architect position include developing and analyzing the design and architecture of complex software application systems, providing architectural and implementation oversight, analyzing and documenting existing systems, communicating technical issues clearly, writing and debugging complex problems in various software modules, managing test and acceptance activities, designing and building reusable modules, writing application code using latest C# and ASP.NET framework, assisting in building database structure for SQL Server, understanding cloud engineering, handling and prioritizing multiple tasks, demonstrating strong analytical and problem solving skills, having very good communication skills, having 10+ years of professional web development experience using C#, .NET, ASP.NET 3.5 – 4.0, MVC, and WCF, having 7+ year’s professional experience with SQL Server 2012 and up, having hands-on experience with HTML5, CSS3, Javascript, understanding of XML/Web services, having a Bachelor’s degree or equivalent in a relevant discipline, and having experience with agile software development, Test Driven Development (TDD), and Cloud IVR, Live Video Chat, Chat and texting web integration.\n\nComparison with dataset answer:\nF1:0.08 BLEU:0.00 EM:0.00\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Few-Shot Prompt (1-Shot)\n\nWe manually construct a prompt that includes one example (1-shot learning). This tests the model's ability to learn from a single example.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_data[\"len\"]=test_data[\"context\"].apply(len)\nsamples=test_data.sort_values(by=\"len\").head(2)\nshots=samples.head(1)\ntest_sample=samples.iloc[-1]\npromt=\"\"\nindex=1\nfor i,row in shots.iterrows():\n    example=f\"Example {index} question: {row['question']} context: {row['context']} answer: {row['answer']}\\n\"\n    promt+=example\n    index+=1\npromt+=f\"question: {test_sample['question']} context: {test_sample['context']} answer:\"\nprint(promt)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:46.496065Z",
     "iopub.execute_input": "2025-05-24T00:29:46.496282Z",
     "iopub.status.idle": "2025-05-24T00:29:46.506567Z",
     "shell.execute_reply.started": "2025-05-24T00:29:46.496264Z",
     "shell.execute_reply": "2025-05-24T00:29:46.505879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Example 1 question: Who is the speaker for the lecture on Numerical Characterization of Powder Flowability? context: 【学术活动预告】numerical characterization of powder flowability/粉体流动性的计算模拟研究 报告题目：numerical characterization of powder flowability/粉体流动性的计算模拟研究 报告人：裴春雷 博士 英国剑桥大学材料科学及冶金系博士后 时 间：2018年1月2日（周二）下午15:30 地 点：紫金校区能源学院学术报告厅（一教237） 邀请人：南京师范大学能源与机械工程学院、江苏省“能源系统过程转化与减排技术”工程实验室 biography:. answer: The speaker for the lecture on Numerical Characterization of Powder Flowability is Dr. Pei Chunlei from the University of Cambridge's Department of Materials Science and Metallurgy.\nquestion: What are some of the popular locations for Mandolin lessons near Hazelwood, MO? context: hazelwood, mo mandolin lessons looking for private in-home or in-studio mandolin hazelwood, mo check out some of our most popular teachers near hazelwood, mo including maryland heights, florissant, bridgeton, earth city and saint ann. brandon f.close _15<< · mandolin · in home brandon f. brandon f. about leanna f.close _19<<.jpg) leanna f. .jpg) leanna f. about ani k.close violin · online · violin · online · violin · online ani k. ani k. about jake h.close _28<< · mandolin · in home · · jake h. jake h. about toni d.close _33<< toni d. toni d. about dennis c.close _36<< · acoustic guitar · in studio dennis c. << answer:\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "model_T5_pretrained.eval()\ninputs = tokenizer_T5(promt, return_tensors=\"pt\", max_length=2048, truncation=True)\ninputs = {k: v.to(device) for k, v in inputs.items()}\nwith torch.no_grad():\n    outputs = model_T5_pretrained.generate(\n        **inputs,\n        max_length=128,\n        num_beams=4,\n        early_stopping=True\n    )\ngen_answer_1_shot=tokenizer_T5.decode(outputs[0], skip_special_tokens=True).strip()\ngen_answer_zero_shot=generate_answer(model_T5_pretrained, tokenizer_T5, question=test_sample['question'], device=device, max_input_length=512, max_output_length=64, context=test_sample['context'])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:46.507298Z",
     "iopub.execute_input": "2025-05-24T00:29:46.507539Z",
     "iopub.status.idle": "2025-05-24T00:29:46.970403Z",
     "shell.execute_reply.started": "2025-05-24T00:29:46.507521Z",
     "shell.execute_reply": "2025-05-24T00:29:46.969845Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": "### Let's compare the generated answer with the real one",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(f\"Question: {test_sample['question']}\\nGenereated one shot answer:{gen_answer_1_shot}\\nGenereated zero shot answer:{gen_answer_zero_shot}\\nDataset Answer:{test_sample['answer']}\")\nprint(f\"Comparison with real answer \\nF1:{f1_score(gen_answer_1_shot,test_sample['answer']):.2f} BLEU:{bleu_score(gen_answer_1_shot,test_sample['answer']):.2f} EM:{exact_match_score(gen_answer_1_shot,test_sample['answer']):.2f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:46.971135Z",
     "iopub.execute_input": "2025-05-24T00:29:46.971349Z",
     "iopub.status.idle": "2025-05-24T00:29:46.976707Z",
     "shell.execute_reply.started": "2025-05-24T00:29:46.971332Z",
     "shell.execute_reply": "2025-05-24T00:29:46.976198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Question: What are some of the popular locations for Mandolin lessons near Hazelwood, MO?\nGenereated one shot answer:maryland heights, florissant, bridgeton, earth city and saint ann\nGenereated zero shot answer:maryland heights, florissant, bridgeton, earth city and saint ann\nDataset Answer:Some of the popular locations for Mandolin lessons near Hazelwood, MO are Maryland Heights, Florissant, Bridgeton, Earth City and Saint Ann.\nComparison with real answer \nF1:0.62 BLEU:0.31 EM:0.00\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "#### Aggregate Performance of zero shot calculated on test data (15% all data)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#avg_bleu, avg_em, avg_f1=eval_answers(model_T5_pretrained, tokenizer_T5,test_data,max_input=512,max_output=64)\nprint_scores(model_name=\"t5_zero_shot\",use_backup=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:46.978766Z",
     "iopub.execute_input": "2025-05-24T00:29:46.978972Z",
     "iopub.status.idle": "2025-05-24T00:29:47.009780Z",
     "shell.execute_reply.started": "2025-05-24T00:29:46.978957Z",
     "shell.execute_reply": "2025-05-24T00:29:47.009127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Scores of t5_zero_shot model :\nAverage BLEU score: 2.69\nExact Match: 0.30%\nF1 Score: 19.71%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Zero-Shot Evaluation Without Context\n\nThis step evaluates the model in a context-free setting to understand how much background information contributes to performance.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#avg_bleu, avg_em, avg_f1=eval_answers(model_T5_pretrained,tokenizer_T5,test_data,no_context=True)\nprint_scores(model_name=\"t5_zero_shot_no_context\",use_backup=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:47.010722Z",
     "iopub.execute_input": "2025-05-24T00:29:47.010967Z",
     "iopub.status.idle": "2025-05-24T00:29:47.018013Z",
     "shell.execute_reply.started": "2025-05-24T00:29:47.010946Z",
     "shell.execute_reply": "2025-05-24T00:29:47.017489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Scores of t5_zero_shot_no_context model :\nAverage BLEU score: 1.53\nExact Match: 0.00%\nF1 Score: 15.93%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Model Fine-Tuning\n\nWe fine-tune the pre-trained T5-small model on our QA dataset. This helps the model adapt to the specific language and structure of the task.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n\ntokenizer_T5_tuned = T5Tokenizer.from_pretrained(\"t5-small\")\nmodel_T5_tuned = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\nmodel_T5_tuned.to(device)\ntrain,val = train_test_split(finetuning_data, test_size=0.2, random_state=42)\ntrain_dataset = Dataset.from_pandas(train)\nval_dataset = Dataset.from_pandas(val)\ntokenizer=tokenizer_T5_tuned\ntrain_dataset = train_dataset.map(preprocess,batched=False,fn_kwargs={\n        \"tokenizer\":tokenizer_T5_tuned,\n        \"max_length_input\": 512,\n        \"max_length_labels\": 64\n    })\nval_dataset = val_dataset.map(preprocess,batched=False,fn_kwargs={\n        \"tokenizer\":tokenizer_T5_tuned,\n        \"max_length_input\": 512,\n        \"max_length_labels\": 64\n    })\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working\",\n    do_train=True,\n    do_eval=True,\n    learning_rate=0.000472,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=6,\n    weight_decay=0.041494,\n    logging_dir=\"./logs\",\n    logging_steps=500,\n    save_steps=1000,     \n    eval_steps=1000,      \n    save_total_limit=2,\n    report_to=\"none\",\n)\ntrainer = Trainer(\n    model=model_T5_tuned,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer_T5_tuned\n)\ntrainer.train()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:29:47.018766Z",
     "iopub.execute_input": "2025-05-24T00:29:47.019062Z",
     "iopub.status.idle": "2025-05-24T00:46:52.436808Z",
     "shell.execute_reply.started": "2025-05-24T00:29:47.019045Z",
     "shell.execute_reply": "2025-05-24T00:46:52.436244Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/6124 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9052302bbc6849cfa75d40e6437a3feb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/1531 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ffe436878214814a7c395a1ba7885d6"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_35/2746039429.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='9186' max='9186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9186/9186 16:36, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.006500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.893800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.836000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.720900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.701300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.706500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.612800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.611600</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.619600</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.527000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.538000</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.512300</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.486800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.455200</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.456700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.463200</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.411800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.398500</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "TrainOutput(global_step=9186, training_loss=0.6053531737258018, metrics={'train_runtime': 996.5277, 'train_samples_per_second': 36.872, 'train_steps_per_second': 9.218, 'total_flos': 4972999153287168.0, 'train_loss': 0.6053531737258018, 'epoch': 6.0})"
     },
     "metadata": {}
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "#save \ntrainer.save_model(\"/kaggle/working/trainer\")\ntokenizer_T5_tuned.save_pretrained(\"/kaggle/working/tokenizer\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:49:02.198785Z",
     "iopub.execute_input": "2025-05-24T00:49:02.199112Z",
     "iopub.status.idle": "2025-05-24T00:49:02.800339Z",
     "shell.execute_reply.started": "2025-05-24T00:49:02.199073Z",
     "shell.execute_reply": "2025-05-24T00:49:02.799584Z"
    }
   },
   "outputs": [
    {
     "execution_count": 18,
     "output_type": "execute_result",
     "data": {
      "text/plain": "('/kaggle/working/tokenizer/tokenizer_config.json',\n '/kaggle/working/tokenizer/special_tokens_map.json',\n '/kaggle/working/tokenizer/spiece.model',\n '/kaggle/working/tokenizer/added_tokens.json')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "#load\ntokenizer_T5_tuned = T5Tokenizer.from_pretrained(\"/kaggle/input/trained-nlp-models/tokenizer_t5/tokenizer\")\nmodel_T5_tuned = T5ForConditionalGeneration.from_pretrained(\"/kaggle/input/trained-nlp-models/model_t5/trainer\")\nmodel_T5_tuned.to(device)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:46:52.908022Z",
     "iopub.execute_input": "2025-05-24T00:46:52.908302Z",
     "iopub.status.idle": "2025-05-24T00:46:55.567814Z",
     "shell.execute_reply.started": "2025-05-24T00:46:52.908279Z",
     "shell.execute_reply": "2025-05-24T00:46:55.567241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": "### Evaluation: Fine-Tuned Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#avg_bleu, avg_em, avg_f1=eval_answers(model_T5_tuned,tokenizer_T5_tuned,test_data,max_input=512,max_output=64)\nprint_scores(model_name=\"t5_tuned\",use_backup=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:46:55.568511Z",
     "iopub.execute_input": "2025-05-24T00:46:55.568775Z",
     "iopub.status.idle": "2025-05-24T00:46:55.581404Z",
     "shell.execute_reply.started": "2025-05-24T00:46:55.568748Z",
     "shell.execute_reply": "2025-05-24T00:46:55.580838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Scores of t5_tuned model :\nAverage BLEU score: 39.32\nExact Match: 10.11%\nF1 Score: 59.45%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": "### let's test the previus answer",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "tuned_model_answer=generate_answer(model_T5_tuned, tokenizer_T5_tuned, question=sample_zero_shot[\"question\"].values[0], device=device, max_input_length=512, max_output_length=64, context=sample_zero_shot[\"context\"].values[0])\nsample_zero_shot[\"question\"].values[0],tuned_model_answer, sample_zero_shot[\"answer\"].values[0]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:46:55.582076Z",
     "iopub.execute_input": "2025-05-24T00:46:55.582329Z",
     "iopub.status.idle": "2025-05-24T00:46:56.335848Z",
     "shell.execute_reply.started": "2025-05-24T00:46:55.582313Z",
     "shell.execute_reply": "2025-05-24T00:46:56.335109Z"
    }
   },
   "outputs": [
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": "('What are the responsibilities and requirements for the Software Architect position at the entertainment company?',\n 'The responsibilities and requirements for the Software Architect position at the entertainment company include developing and analysing the design and architecture of complex software application systems, providing architectural and implementation oversight and guidance to ensure consistency and quality of design and code, analyzing and documenting existing systems, reviewing preexisting complex code',\n 'The responsibilities and requirements for the Software Architect position include developing and analyzing the design and architecture of complex software application systems, providing architectural and implementation oversight, analyzing and documenting existing systems, communicating technical issues clearly, writing and debugging complex problems in various software modules, managing test and acceptance activities, designing and building reusable modules, writing application code using latest C# and ASP.NET framework, assisting in building database structure for SQL Server, understanding cloud engineering, handling and prioritizing multiple tasks, demonstrating strong analytical and problem solving skills, having very good communication skills, having 10+ years of professional web development experience using C#, .NET, ASP.NET 3.5 – 4.0, MVC, and WCF, having 7+ year’s professional experience with SQL Server 2012 and up, having hands-on experience with HTML5, CSS3, Javascript, understanding of XML/Web services, having a Bachelor’s degree or equivalent in a relevant discipline, and having experience with agile software development, Test Driven Development (TDD), and Cloud IVR, Live Video Chat, Chat and texting web integration.')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Hyperparameter Tuning on 15% of the Dataset\n\nIn order to optimize the T5 model performance, we performed a hyperparameter tuning process using only 15% of the training dataset. \n\nThe following table summarizes the results of 27 different trials. Each trial is evaluated using a composite value score, which considers BLEU, EM, and F1. The best performing configurations are those with the highest `value`.\n\nHyperparameters tuned:\n- **Learning Rate (lr)**: Controls how fast the model adapts during training.\n- **Batch Size**: Affects stability and memory usage during training.\n- **Epochs**: Number of times the model sees the entire dataset.\n- **Learning Rate Scheduler (lr_sched)**: Strategy to adjust the learning rate over time.\n- **Weight Decay**: Regularization term to prevent overfitting.\n\n### Results \nBelow is the table with trial configurations and their corresponding scores:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import optuna \nstudy = optuna.load_study(\n        study_name='t5_small',\n        storage=f'sqlite:////kaggle/input/nlp-resources/t5_small_hyper_parameter_tuning.db')\nimport pandas as pd\ndata = []\nfor trial in study.trials:\n    trial_data = trial.params.copy()\n    trial_data.update(trial.user_attrs)\n    trial_data[\"value\"] = trial.value  # score o loss principale\n    trial_data[\"trial_number\"] = trial.number\n    data.append(trial_data)\n\ntrials_df = pd.DataFrame(data)[:27]\ntrials_df\n",
   "metadata": {
    "trusted": true,
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2025-05-24T00:46:56.336675Z",
     "iopub.execute_input": "2025-05-24T00:46:56.337213Z",
     "iopub.status.idle": "2025-05-24T00:46:58.017420Z",
     "shell.execute_reply.started": "2025-05-24T00:46:56.337187Z",
     "shell.execute_reply": "2025-05-24T00:46:58.016832Z"
    }
   },
   "outputs": [
    {
     "execution_count": 17,
     "output_type": "execute_result",
     "data": {
      "text/plain": "          lr  batch  epochs lr_sched  weight_decay       BLEU         EM  \\\n0   0.000011      8       2   linear      0.009554   4.062378   1.096892   \n1   0.000116      4       5   cosine      0.035746  40.541588  10.847044   \n2   0.000012      8       6   linear      0.014758  34.300564   7.800122   \n3   0.000417      4       2   linear      0.049547  39.362632  10.115783   \n4   0.000014      4       4   cosine      0.034493  34.996220   8.409506   \n5   0.000161      4       6   cosine      0.037204  40.901913  11.151737   \n6   0.000198      8       3   linear      0.030070  40.097911  11.090798   \n7   0.000041      8       5   linear      0.027798  37.740979   9.567337   \n8   0.000026      8       5   cosine      0.001707  36.188469   9.140768   \n9   0.000182      8       2   linear      0.011389  38.367603  10.176722   \n10  0.000472      4       6   cosine      0.041494  42.060406  11.578306   \n11  0.000488      4       6   cosine      0.045539  41.766182  11.578306   \n12  0.000491      4       6   cosine      0.048628  41.277081   9.872029   \n13  0.000305      4       4   cosine      0.043324  40.957572  11.395491   \n14  0.000075      4       6   cosine      0.020777  40.023873  10.603291   \n15  0.000241      4       5   cosine      0.042620  40.958226  10.847044   \n16  0.000334      4       4   cosine      0.042188  41.132566  11.273614   \n17  0.000104      4       6   cosine      0.044663  40.530561  11.029860   \n18  0.000046      4       3   cosine      0.024695  37.615632   9.445460   \n19  0.000495      4       5   cosine      0.038174  41.569505  10.786106   \n20  0.000287      4       6   cosine      0.030440  41.583717  11.212675   \n21  0.000298      4       6   cosine      0.031439  41.725203  10.786106   \n22  0.000324      4       6   cosine      0.022303  41.052979  10.725168   \n23  0.000129      4       5   cosine      0.039694  40.708535  11.090798   \n24  0.000230      4       6   cosine      0.046717  41.854179  10.786106   \n25  0.000231      4       5   cosine      0.032745  41.738021  10.847044   \n26  0.000074      4       6   cosine      0.048155  39.997187  10.481414   \n\n           F1      value  trial_number  \n0    6.564946   4.674273             0  \n1   61.165567  44.007612             1  \n2   55.112598  38.837651             2  \n3   59.778431  42.838056             3  \n4   55.623600  39.396634             4  \n5   61.257725  44.190348             5  \n6   60.592315  43.692420             6  \n7   58.488850  41.737609             7  \n8   56.976599  40.547037             8  \n9   59.046327  42.317573             9  \n10  62.272108  45.042797            10  \n11  61.641823  44.635204            11  \n12  61.530903  44.007858            12  \n13  61.155984  44.207995            13  \n14  60.841980  43.688563            14  \n15  61.276554  44.115868            15  \n16  61.338639  44.298524            16  \n17  60.981637  43.950996            17  \n18  58.212524  41.522716            18  \n19  61.612929  44.360540            19  \n20  61.886982  44.654364            20  \n21  62.006156  44.612046            21  \n22  61.272741  44.086493            22  \n23  61.303343  44.180099            23  \n24  62.197484  44.739740            24  \n25  62.018139  44.638799            25  \n26  60.900112  43.684210            26  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lr</th>\n      <th>batch</th>\n      <th>epochs</th>\n      <th>lr_sched</th>\n      <th>weight_decay</th>\n      <th>BLEU</th>\n      <th>EM</th>\n      <th>F1</th>\n      <th>value</th>\n      <th>trial_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000011</td>\n      <td>8</td>\n      <td>2</td>\n      <td>linear</td>\n      <td>0.009554</td>\n      <td>4.062378</td>\n      <td>1.096892</td>\n      <td>6.564946</td>\n      <td>4.674273</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000116</td>\n      <td>4</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.035746</td>\n      <td>40.541588</td>\n      <td>10.847044</td>\n      <td>61.165567</td>\n      <td>44.007612</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000012</td>\n      <td>8</td>\n      <td>6</td>\n      <td>linear</td>\n      <td>0.014758</td>\n      <td>34.300564</td>\n      <td>7.800122</td>\n      <td>55.112598</td>\n      <td>38.837651</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000417</td>\n      <td>4</td>\n      <td>2</td>\n      <td>linear</td>\n      <td>0.049547</td>\n      <td>39.362632</td>\n      <td>10.115783</td>\n      <td>59.778431</td>\n      <td>42.838056</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000014</td>\n      <td>4</td>\n      <td>4</td>\n      <td>cosine</td>\n      <td>0.034493</td>\n      <td>34.996220</td>\n      <td>8.409506</td>\n      <td>55.623600</td>\n      <td>39.396634</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000161</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.037204</td>\n      <td>40.901913</td>\n      <td>11.151737</td>\n      <td>61.257725</td>\n      <td>44.190348</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000198</td>\n      <td>8</td>\n      <td>3</td>\n      <td>linear</td>\n      <td>0.030070</td>\n      <td>40.097911</td>\n      <td>11.090798</td>\n      <td>60.592315</td>\n      <td>43.692420</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000041</td>\n      <td>8</td>\n      <td>5</td>\n      <td>linear</td>\n      <td>0.027798</td>\n      <td>37.740979</td>\n      <td>9.567337</td>\n      <td>58.488850</td>\n      <td>41.737609</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000026</td>\n      <td>8</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.001707</td>\n      <td>36.188469</td>\n      <td>9.140768</td>\n      <td>56.976599</td>\n      <td>40.547037</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000182</td>\n      <td>8</td>\n      <td>2</td>\n      <td>linear</td>\n      <td>0.011389</td>\n      <td>38.367603</td>\n      <td>10.176722</td>\n      <td>59.046327</td>\n      <td>42.317573</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.000472</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.041494</td>\n      <td>42.060406</td>\n      <td>11.578306</td>\n      <td>62.272108</td>\n      <td>45.042797</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.000488</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.045539</td>\n      <td>41.766182</td>\n      <td>11.578306</td>\n      <td>61.641823</td>\n      <td>44.635204</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000491</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.048628</td>\n      <td>41.277081</td>\n      <td>9.872029</td>\n      <td>61.530903</td>\n      <td>44.007858</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000305</td>\n      <td>4</td>\n      <td>4</td>\n      <td>cosine</td>\n      <td>0.043324</td>\n      <td>40.957572</td>\n      <td>11.395491</td>\n      <td>61.155984</td>\n      <td>44.207995</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.000075</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.020777</td>\n      <td>40.023873</td>\n      <td>10.603291</td>\n      <td>60.841980</td>\n      <td>43.688563</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.000241</td>\n      <td>4</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.042620</td>\n      <td>40.958226</td>\n      <td>10.847044</td>\n      <td>61.276554</td>\n      <td>44.115868</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.000334</td>\n      <td>4</td>\n      <td>4</td>\n      <td>cosine</td>\n      <td>0.042188</td>\n      <td>41.132566</td>\n      <td>11.273614</td>\n      <td>61.338639</td>\n      <td>44.298524</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.000104</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.044663</td>\n      <td>40.530561</td>\n      <td>11.029860</td>\n      <td>60.981637</td>\n      <td>43.950996</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.000046</td>\n      <td>4</td>\n      <td>3</td>\n      <td>cosine</td>\n      <td>0.024695</td>\n      <td>37.615632</td>\n      <td>9.445460</td>\n      <td>58.212524</td>\n      <td>41.522716</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.000495</td>\n      <td>4</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.038174</td>\n      <td>41.569505</td>\n      <td>10.786106</td>\n      <td>61.612929</td>\n      <td>44.360540</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.000287</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.030440</td>\n      <td>41.583717</td>\n      <td>11.212675</td>\n      <td>61.886982</td>\n      <td>44.654364</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.000298</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.031439</td>\n      <td>41.725203</td>\n      <td>10.786106</td>\n      <td>62.006156</td>\n      <td>44.612046</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.000324</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.022303</td>\n      <td>41.052979</td>\n      <td>10.725168</td>\n      <td>61.272741</td>\n      <td>44.086493</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.000129</td>\n      <td>4</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.039694</td>\n      <td>40.708535</td>\n      <td>11.090798</td>\n      <td>61.303343</td>\n      <td>44.180099</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.000230</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.046717</td>\n      <td>41.854179</td>\n      <td>10.786106</td>\n      <td>62.197484</td>\n      <td>44.739740</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.000231</td>\n      <td>4</td>\n      <td>5</td>\n      <td>cosine</td>\n      <td>0.032745</td>\n      <td>41.738021</td>\n      <td>10.847044</td>\n      <td>62.018139</td>\n      <td>44.638799</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.000074</td>\n      <td>4</td>\n      <td>6</td>\n      <td>cosine</td>\n      <td>0.048155</td>\n      <td>39.997187</td>\n      <td>10.481414</td>\n      <td>60.900112</td>\n      <td>43.684210</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Final Comparison of All Model Configurations\n\nThis table summarizes the performance of all major configurations evaluated throughout the project.\n\n| Model Configuration         | Context Used | Training Type     |On all test data |Exact Match (%) | F1 Score (%) | BLEU Score |\n|----------------------------|--------------|-------------------|-----------------|--------------|------------|------------|\n| Zero-Shot                  | yes           | Pretrained only   | True            | 0.30            | 19.71         | 2.79       |\n| Zero-Shot (No Context)     | no            | Pretrained only   | True            | 0.00            | 15.93         | 1.53       |\n| Few-Shot (1 example)       | yes           | Prompting only    | False (1 sample)            | 0.00            | 62.0         | 31       |\n| Fine-Tuned (Best Config)   | yes           | Supervised tuning | True            | 10.11           | 59.45         | 39.32       |\n",
   "metadata": {}
  }
 ]
}

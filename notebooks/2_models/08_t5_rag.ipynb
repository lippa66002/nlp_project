{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11912806,"sourceType":"datasetVersion","datasetId":7484236,"isSourceIdPinned":true},{"sourceId":11929735,"sourceType":"datasetVersion","datasetId":7398577,"isSourceIdPinned":true}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nThis notebook explores a Retrieval-Augmented Generation\n- Sentence-BERT as a pure retriever.  \n- RAG pipeline using T5-small as the generator.  \n- zero-shot and fine-tuned test  \n\nAll configurations are evaluated using standard metrics like EM, F1, and BLEU.","metadata":{}},{"cell_type":"markdown","source":"## 1. Dataset Loading and Utility Functions","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata=pd.read_parquet(\"/kaggle/input/nlp-resources/cleaned_data.parquet\")\nfinetuning_data=pd.read_parquet(\"/kaggle/input/nlp-resources/tuning_data.parquet\")\nhyperparameter_tuning_data=pd.read_parquet(\"/kaggle/input/nlp-resources/hyperparameter_tuning_data.parquet\")\ntest_data=pd.read_parquet(\"/kaggle/input/nlp-resources/test_data.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:39:28.494131Z","iopub.execute_input":"2025-05-24T06:39:28.494733Z","iopub.status.idle":"2025-05-24T06:39:29.574403Z","shell.execute_reply.started":"2025-05-24T06:39:28.494706Z","shell.execute_reply":"2025-05-24T06:39:29.573582Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import T5Tokenizer\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom transformers import EarlyStoppingCallback\nfrom transformers import TrainerCallback\nfrom functools import reduce\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport string\nimport re\nfrom collections import Counter\nimport numpy as np\nimport pandas as pd\nnltk.download('punkt')\n\ndef preprocess(example,tokenizer,max_length_input=512,max_length_labels=64,no_context=False):\n    input_text = f\"question: {example['question']}\" \n    if (not no_context):\n        input_text+=f\" context: {example['context']}\"\n    target_text = example[\"answer\"]\n    inputs = tokenizer(input_text, max_length=max_length_input, truncation=True, padding=\"max_length\")\n    labels = tokenizer(target_text, max_length=max_length_labels, truncation=True, padding=\"max_length\")[\"input_ids\"] \n    inputs[\"labels\"] =labels\n    return inputs\ndef normalize_answer(s):\n    def remove_articles(text):\n        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n    def remove_punc(text):\n        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n    def white_space_fix(text):\n        return ' '.join(text.split())\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\ndef exact_match_score(prediction, ground_truth):\n    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n\ndef f1_score(prediction, ground_truth):\n    pred_tokens = normalize_answer(prediction).split()\n    gt_tokens = normalize_answer(ground_truth).split()\n    common = Counter(pred_tokens) & Counter(gt_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = num_same / len(pred_tokens)\n    recall = num_same / len(gt_tokens)\n    return 2 * precision * recall / (precision + recall)\n    \ndef bleu_score(prediction, ground_truth):\n    smoothie = SmoothingFunction().method4  # migliora BLEU su frasi corte\n    pred_tokens = nltk.word_tokenize(prediction.lower())\n    gt_tokens = nltk.word_tokenize(ground_truth.lower())\n    return sentence_bleu([gt_tokens], pred_tokens, smoothing_function=smoothie)\n    \ndef get_top_k_contexts(context_embeddings,model_embed,query,k=3):\n    query_emb=model_embed.encode([query], convert_to_numpy=True)\n    similarity=cosine_similarity(query_emb,context_embeddings)[0]\n    top_k_idx = similarity.argsort()[-k:]\n    return [contexts[i] for i in top_k_idx]\n    \ndef eval_answers(model,tokenizer,test_data=test_data,max_input=512,max_output=64, rag=False, no_context=False):\n    exact_matches = []\n    f1_scores = []\n    bleu_scores=[]\n    for idx, row in test_data.iterrows():\n        context= None if no_context else row['context']\n        pred_answer = generate_answer(model, tokenizer, row['question'],max_input_length=max_input,max_output_length=max_output, device=device,context=context )\n        em = exact_match_score(pred_answer, row['answer'])\n        f1 = f1_score(pred_answer, row['answer'])\n        bleu = bleu_score(pred_answer, row['answer'])\n        exact_matches.append(em)\n        f1_scores.append(f1)\n        bleu_scores.append(bleu)\n    return sum(bleu_scores) / len(bleu_scores) * 100,sum(exact_matches) / len(exact_matches) * 100, sum(f1_scores) / len(f1_scores) * 100\ndef print_scores(avg_bleu=-1, avg_em=-1, avg_f1=-1,model_name=\"\",scores_path=\"/kaggle/input/nlp-resources/scores_t5_rag.parquet\",use_backup=False):\n    \n    if(use_backup):\n        scores=pd.read_parquet(scores_path)\n        scores_array=scores[scores[\"model_name\"]==model_name][[\"avg_bleu\",\"avg_em\",\"avg_f1\"]].values[0]\n    else:\n        scores_array=np.array([avg_bleu, avg_em, avg_f1])\n    print(f\"Scores of {model_name} model :\")\n    print(f\"Average BLEU score: {scores_array[0]:.2f}\")\n    print(f\"Exact Match: {scores_array[1]:.2f}%\")\n    print(f\"F1 Score: {scores_array[2]:.2f}%\")\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:39:29.575770Z","iopub.execute_input":"2025-05-24T06:39:29.576044Z","iopub.status.idle":"2025-05-24T06:39:57.927881Z","shell.execute_reply.started":"2025-05-24T06:39:29.576019Z","shell.execute_reply":"2025-05-24T06:39:57.927083Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"2025-05-24 06:39:44.100059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748068784.293917      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748068784.350677      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#da levare\nimport re\nfrom bs4 import BeautifulSoup\n\ndef clean_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\nfinetuning_data[\"context\"]=finetuning_data[\"context\"].apply(lambda x : clean_text(x))\nhyperparameter_tuning_data[\"context\"]=hyperparameter_tuning_data[\"context\"].apply(lambda x : clean_text(x))\ntest_data[\"context\"]=test_data[\"context\"].apply(lambda x : clean_text(x))\ncontexts=pd.concat([test_data[\"context\"],hyperparameter_tuning_data[\"context\"],finetuning_data[\"context\"]]).to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:39:57.928666Z","iopub.execute_input":"2025-05-24T06:39:57.929251Z","iopub.status.idle":"2025-05-24T06:40:01.450648Z","shell.execute_reply.started":"2025-05-24T06:39:57.929230Z","shell.execute_reply":"2025-05-24T06:40:01.449765Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/143321928.py:9: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n\nAssuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n\nIf you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n\n    from bs4 import XMLParsedAsHTMLWarning\n    import warnings\n\n    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n\n  text = BeautifulSoup(text, \"html.parser\").get_text()\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"tokenizer_T5_tuned = T5Tokenizer.from_pretrained(\"/kaggle/input/trained-nlp-models/tokenizer_t5/tokenizer\")\nmodel_T5_tuned = T5ForConditionalGeneration.from_pretrained(\"/kaggle/input/trained-nlp-models/model_t5/trainer\")\nmodel_T5_tuned.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:40:01.452234Z","iopub.execute_input":"2025-05-24T06:40:01.452719Z","iopub.status.idle":"2025-05-24T06:40:04.378837Z","shell.execute_reply.started":"2025-05-24T06:40:01.452700Z","shell.execute_reply":"2025-05-24T06:40:04.378140Z"},"scrolled":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## 2. Pure Retrieval using Sentence-BERT\nSentence-BERT is used to encode and retrieve the most relevant documents, based on the cosine similarity with the query embedding","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport logging, transformers, sentence_transformers\nfrom sentence_transformers import SentenceTransformer, LoggingHandler\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)          \nlogging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\nsentence_transformers.util.tqdm = lambda *args, **kwargs: iter([])\n\nmodel_embed = SentenceTransformer('all-MiniLM-L6-v2') \ncontext_embeddings = model_embed.encode(contexts, convert_to_numpy=True)\n\n#percentage of hits\ndef recall_k(test_data,k):\n    hits=0\n    for i,r in test_data.iterrows():\n        top_contexts=get_top_k_contexts(context_embeddings,model_embed,query=r[\"question\"],k=k)\n        if(r[\"context\"] in top_contexts):\n            hits+=1\n    return hits/len(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:40:04.379597Z","iopub.execute_input":"2025-05-24T06:40:04.379875Z","iopub.status.idle":"2025-05-24T06:40:41.839448Z","shell.execute_reply.started":"2025-05-24T06:40:04.379856Z","shell.execute_reply":"2025-05-24T06:40:41.838824Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d1dda4e2e24d9b9ce3272b24f1af17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a813e8a990d47fc973b5a65c6fd234e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b28eabde924a989f82f4cf542dda6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbb856ac661645d8937c6a7f226599f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5d59d8a72ed4319bf5f9b205eac3d13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"597738eed90540d4a15506cc8da2df90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde53551aad74bce8f590691bddb5c27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2eebe1117d42cebb2f69b9f54ed79e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6061e31ac9c2475f89f2a47222d385ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1e3016ce1254b909844a96fa246ed3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b5f8353c6f408ba2298380a5e8af90"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"for k in [1, 3, 5]:\n    print(f\"Recall@{k}: {recall_k(test_data, k):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:40:41.840210Z","iopub.execute_input":"2025-05-24T06:40:41.840418Z","iopub.status.idle":"2025-05-24T06:42:17.164328Z","shell.execute_reply.started":"2025-05-24T06:40:41.840401Z","shell.execute_reply":"2025-05-24T06:42:17.163565Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Recall@1: 0.80%\nRecall@3: 0.85%\nRecall@5: 0.87%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Sentence-BERT Retrieval Evaluation\nUsing Recall@K metric, with k=1,3 and 5.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nscores=pd.read_parquet(\"/kaggle/input/nlp-resources/scores_t5_rag.parquet\")\nfor i in [1,3,5]:\n    recall=f\"rcall{i}\"\n    print(f\"Recall@{i}: {scores[scores['model_name']=='sb_ctx_retrieval'][recall].values[0]} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:42:17.165335Z","iopub.execute_input":"2025-05-24T06:42:17.165650Z","iopub.status.idle":"2025-05-24T06:42:17.182631Z","shell.execute_reply.started":"2025-05-24T06:42:17.165619Z","shell.execute_reply":"2025-05-24T06:42:17.181877Z"}},"outputs":[{"name":"stdout","text":"Recall@1: 0.8 \nRecall@3: 0.85 \nRecall@5: 0.87 \n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 3. RAG Pipeline with T5-small as answer generator\n- **Sentence-BERT**: used to retrieve the most relevant context chunks for a given question.\n- **T5-small**: used to generate an answer based on the retrieved context.\n### Retrieval Strategy (`on_top_chunk` flag)\n\nWe support two generation strategies controlled by the `on_top_chunk` flag:\n\n- `on_top_chunk = True` (default):  \n  Only the **top-ranked** context chunk (based on Sentence-BERT similarity with the query) is passed to T5 for answer generation.\n\n- `on_top_chunk = False`:  \n  The model generates **one answer for each retrieved chunk**.  \n  Then, a **cross-encoder** is used to **score and select the best answer** among all candidates.  \n  ","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import CrossEncoder\nclass ChunkRag:\n    def __init__(\n        self,\n        corpus_contexts,\n        retriever_name=\"all-MiniLM-L6-v2\",\n        qa_name=\"t5-small\",\n        crossencoder_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n        qa_tok=None,\n        qa_model=None,\n        device=None,\n    ):\n        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        self.embedder = SentenceTransformer(retriever_name, device=self.device)\n        self.embedder.eval()\n        self.cross_encoder = CrossEncoder(crossencoder_name, device=self.device)\n        self.qa_tok = qa_tok if qa_tok else T5Tokenizer.from_pretrained(qa_name)\n        self.qa_model = qa_model if qa_model else T5ForConditionalGeneration.from_pretrained(qa_name).to(self.device).eval()\n\n        self.contexts = corpus_contexts\n        with torch.no_grad():\n            self.ctx_emb = self.embedder.encode(corpus_contexts, convert_to_tensor=True, normalize_embeddings=True)\n    def chunk_text(self ,text,  max_tokens=512, stride=None):\n        if stride is None or stride >= max_tokens:\n            stride = max_tokens\n    \n        ids = self.qa_tok.encode(text, add_special_tokens=False)\n        chunks = []\n        start = 0\n        while start < len(ids):\n            end = min(start + max_tokens, len(ids))\n            chunk_ids = ids[start:end]\n            chunks.append(self.qa_tok.decode(chunk_ids))\n            if end == len(ids):\n                break\n            start += stride\n        return chunks      \n    def _get_topk(self, question, k):\n        q_emb = self.embedder.encode(question, convert_to_tensor=True, normalize_embeddings=True)\n\n        scores = sentence_transformers.util.cos_sim(q_emb, self.ctx_emb)[0].cpu()\n        best = torch.topk(scores, k=k).indices.cpu().tolist()\n        return [self.contexts[i] for i in best],self.contexts[np.argmax(scores)]\n    def pick_best(self, question, answers):\n        pairs = [[question, ans] for ans in answers]\n        scores = self.cross_encoder.predict(pairs)\n        best_idx = np.argmax(scores)\n        return answers[best_idx]\n\n    def answer(self, question, top_k=3, on_top_chunk=True,\n               max_tokens=512, stride=None):\n        top_contexts,top_ctx = self._get_topk(question, k=top_k)\n\n        all_chunks = []\n        for ctx in top_contexts:\n            all_chunks.extend(\n                self.chunk_text(ctx)\n            )\n\n        if on_top_chunk:\n            best_answer = self._generate_answer(question, top_ctx)\n        else:\n            candidate_answers = [\n                self._generate_answer(question, ch) for ch in all_chunks\n            ]\n            best_answer = self.pick_best(question, candidate_answers)\n    \n        return best_answer\n        \n    def _generate_answer(self, question, context):\n        input_text = f\"question: {question} context: {context}\"\n        inputs = self.qa_tok(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(self.device)\n        outputs = self.qa_model.generate(\n            **inputs,\n            max_length=64,\n            num_beams=4,\n            early_stopping=True\n        )\n        return self.qa_tok.decode(outputs[0], skip_special_tokens=True)\n    def eval(self,test_data,on_top_chunk=True):\n        exact_matches = []\n        f1_scores = []\n        bleu_scores=[]\n        for idx, row in test_data.iterrows():\n            pred_answer = self.answer(row[\"question\"],on_top_chunk=on_top_chunk)\n            em = exact_match_score(pred_answer, row['answer'])\n            f1 = f1_score(pred_answer, row['answer'])\n            bleu = bleu_score(pred_answer, row['answer'])\n            exact_matches.append(em)\n            f1_scores.append(f1)\n            bleu_scores.append(bleu)\n        return sum(bleu_scores) / len(bleu_scores) * 100,sum(exact_matches) / len(exact_matches) * 100, sum(f1_scores) / len(f1_scores) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:42:17.183389Z","iopub.execute_input":"2025-05-24T06:42:17.183697Z","iopub.status.idle":"2025-05-24T06:42:17.197036Z","shell.execute_reply.started":"2025-05-24T06:42:17.183671Z","shell.execute_reply":"2025-05-24T06:42:17.196356Z"},"scrolled":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"rag_tuned_model=ChunkRag(corpus_contexts=contexts,qa_tok=tokenizer_T5_tuned,qa_model=model_T5_tuned)\nrag_model=ChunkRag(corpus_contexts=contexts)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-05-24T06:42:17.197889Z","iopub.execute_input":"2025-05-24T06:42:17.198142Z","iopub.status.idle":"2025-05-24T06:43:04.955724Z","shell.execute_reply.started":"2025-05-24T06:42:17.198123Z","shell.execute_reply":"2025-05-24T06:43:04.955120Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28050aef944418cbc8961510d44756a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b04b2395d54391be635bea207ce22b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315e9be6172b4166b21a51d88a8dde45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd96bb7c33d4b818a47e36b1baf5c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0b1c2db39e74e79adb87a1b0f504fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6002239bfe4fa098378a2d662796a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e34a2c811344338a4de544b9605e3fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"695b49f89fd34f319e7a3e025e7c3c7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8df57baf25f4017a1b3a94c744a157b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1d8e91092f4d87a26f26f10bc56728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1eaab335f7c4aa885897d8e77e5249b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e01f4cc64494d68a100bcf3713687f7"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"#sample an example\nsample=test_data.sample(n=1,random_state=42)\nsample[\"question\"].values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:53:19.520781Z","iopub.execute_input":"2025-05-24T06:53:19.521049Z","iopub.status.idle":"2025-05-24T06:53:19.527340Z","shell.execute_reply.started":"2025-05-24T06:53:19.521031Z","shell.execute_reply":"2025-05-24T06:53:19.526698Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'What are the responsibilities and requirements for the Software Architect position at the entertainment company?'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"sample[\"context\"].values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:53:43.723653Z","iopub.execute_input":"2025-05-24T06:53:43.723938Z","iopub.status.idle":"2025-05-24T06:53:43.729291Z","shell.execute_reply.started":"2025-05-24T06:53:43.723913Z","shell.execute_reply":"2025-05-24T06:53:43.728515Z"},"scrolled":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'an entertainment company specializing in advice-based products and services is looking for a software architect to work alongside their growing team, as a contractor. responsibilities and requirements -develop and analyze the design and architecture of complex software application systems. -provide architectural and implementation oversight and guidance to ensure consistency and quality of design and code. -analyze and document existing systems, review preexisting complex code and provide recommendations to improve performance & maintainability. -ability to communicate technical issues and concepts clearly, both orally and in writing -write test and debug complex problems in various modules of the various software application -code reviews -manage test and acceptance activities -direct contribution to development and test efforts -manage and support system deployment- -design and build reusable modules to be used throughout our applications -collaborate with senior developers to design and create the next generation of our software, services and systems architecture. -write application code using latest c# and asp.net framework -assist in building database structure for sql server to meet software data storage needs -understand cloud engineering, data streaming, high availability systems, high performance computing and grid computing. -ability to handle and prioritize multiple tasks while managing day to day transactions -self-motivated team player with the ability to work independently -strong analytical and problem solving skills -attention to detail and accuracy -communication skills and ability to work collaboratively with other departments -ability to gracefully shift priorities and be able to handle change -committed to company mission and customer’s needs -transfers thoughts and expresses ideas effectively individually or in a group setting -demonstrates a high level of dependability in doing their job and being there for his/her team -develops cooperation and teamwork and works towards solutions that general benefit all parties involved -very good communication skills, self-motivated, “go getter” kind of person required -10+ years of professional web development experience using c#, .net, asp.net 3.5 – 4.0, mvc, and wcf -10+ years design and development experience of enterprise applications using common development and execution platforms (e.g. j2ee, .net) -7+ year’s professional experience with sql server 2012 and up as well as transact-sql. solid understanding of stored procedures, triggers, database design and relational design -hands-on experience with html5, css3, javascript. -experience with time sensitive & highly optimized rest api & windows services -understanding of xml/web services -knowledge in technological approach as well as in product feature -bachelor’s degree or equivalent in a relevant discipline. -experience with agile software development (specifically scrum) -experience with test driven development (tdd) -experience with cloud ivr, live video chat, chat and texting web integration.'"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## 4. Aggregated performance\n- Tuned T5 on top chunk `on_top_chunk = True`\n- Tuned T5 on top answer `on_top_chunk = False`\n- Zero-Shot on top answer `on_top_chunk = False`\n- Zero-Shot on top chunk `on_top_chunk = True`","metadata":{}},{"cell_type":"markdown","source":"Zero shot performance","metadata":{}},{"cell_type":"code","source":"#avg_bleu, avg_em, avg_f1=rag_model.eval(test_data)\n#print_scores(avg_bleu, avg_em, avg_f1)\n#avg_bleu, avg_em, avg_f1=rag_model.eval(test_data,on_top_chunk=False)\n#print_scores(avg_bleu, avg_em, avg_f1)\n\nprint_scores(model_name=\"rag_zero_shot_best_answer\",use_backup=True)\nprint_scores(model_name=\"rag_zero_shot_best_chunk\",use_backup=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T06:43:33.676912Z","iopub.execute_input":"2025-05-24T06:43:33.677289Z","iopub.status.idle":"2025-05-24T06:43:33.692800Z","shell.execute_reply.started":"2025-05-24T06:43:33.677266Z","shell.execute_reply":"2025-05-24T06:43:33.692105Z"}},"outputs":[{"name":"stdout","text":"Scores of rag_zero_shot_best_answer model :\nAverage BLEU score: 1.43\nExact Match: 0.06%\nF1 Score: 10.76%\nScores of rag_zero_shot_best_chunk model :\nAverage BLEU score: 2.71\nExact Match: 0.06%\nF1 Score: 17.51%\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Evaluating zero shot for the sampled example :","metadata":{}},{"cell_type":"code","source":"zero_shot_answer_top_chunk=rag_model.answer(sample[\"question\"].values[0])\nzero_shot_answer_top_answer=rag_model.answer(sample[\"question\"].values[0],on_top_chunk=False)\nzero_shot_answer_top_answer,zero_shot_answer_top_chunk,sample[\"answer\"].values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:04:13.974300Z","iopub.execute_input":"2025-05-24T07:04:13.974857Z","iopub.status.idle":"2025-05-24T07:04:15.752361Z","shell.execute_reply.started":"2025-05-24T07:04:13.974835Z","shell.execute_reply":"2025-05-24T07:04:15.751601Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('provide pre-sales consulting, analysis, design for networking solutions including assessments, road mapping, architecture/design/deployment/migration projects',\n 'the appropriate technology skills, professional experience, knowledge of the industry’s best practice, the agility to deal with any kind of technology, and a can-do attitude',\n 'The responsibilities and requirements for the Software Architect position include developing and analyzing the design and architecture of complex software application systems, providing architectural and implementation oversight, analyzing and documenting existing systems, communicating technical issues clearly, writing and debugging complex problems in various software modules, managing test and acceptance activities, designing and building reusable modules, writing application code using latest C# and ASP.NET framework, assisting in building database structure for SQL Server, understanding cloud engineering, handling and prioritizing multiple tasks, demonstrating strong analytical and problem solving skills, having very good communication skills, having 10+ years of professional web development experience using C#, .NET, ASP.NET 3.5 – 4.0, MVC, and WCF, having 7+ year’s professional experience with SQL Server 2012 and up, having hands-on experience with HTML5, CSS3, Javascript, understanding of XML/Web services, having a Bachelor’s degree or equivalent in a relevant discipline, and having experience with agile software development, Test Driven Development (TDD), and Cloud IVR, Live Video Chat, Chat and texting web integration.')"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(\"Comparisons with dataset answer, on top_answer: \"+\nf\"\\nF1:{f1_score(zero_shot_answer_top_answer, sample['answer'].values[0]):.2f}\",\n      f\"BLEU:{bleu_score(zero_shot_answer_top_answer, sample['answer'].values[0]):.2f}\",\nf\"EM:{exact_match_score(zero_shot_answer_top_answer, sample['answer'].values[0]):.2f}\",\"\\non context chunk: \"+\nf\"\\nF1:{f1_score(zero_shot_answer_top_chunk, sample['answer'].values[0]):.2f}\",\n      f\"BLEU:{bleu_score(zero_shot_answer_top_chunk, sample['answer'].values[0]):.2f}\",\nf\"EM:{exact_match_score(zero_shot_answer_top_chunk, sample['answer'].values[0]):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:13:23.296979Z","iopub.execute_input":"2025-05-24T07:13:23.297261Z","iopub.status.idle":"2025-05-24T07:13:23.310102Z","shell.execute_reply.started":"2025-05-24T07:13:23.297243Z","shell.execute_reply":"2025-05-24T07:13:23.309308Z"}},"outputs":[{"name":"stdout","text":"Comparisons with dataset answer, on top_answer: \nF1:0.02 BLEU:0.00 EM:0.00 \non context chunk: \nF1:0.08 BLEU:0.00 EM:0.00\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Tuned Q&A model performance","metadata":{}},{"cell_type":"code","source":"#avg_bleu, avg_em, avg_f1=rag_model.eval(test_data)\n#print_scores(avg_bleu, avg_em, avg_f1)\n#avg_bleu, avg_em, avg_f1=rag_model.eval(test_data,on_top_chunk=False)\n#print_scores(avg_bleu, avg_em, avg_f1)\n\nprint_scores(model_name=\"rag_best_answer\",use_backup=True)\nprint_scores(model_name=\"rag_best_chunk\",use_backup=True)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-05-24T06:43:36.577313Z","iopub.execute_input":"2025-05-24T06:43:36.577914Z","iopub.status.idle":"2025-05-24T06:43:36.591525Z","shell.execute_reply.started":"2025-05-24T06:43:36.577889Z","shell.execute_reply":"2025-05-24T06:43:36.590914Z"}},"outputs":[{"name":"stdout","text":"Scores of rag_best_answer model :\nAverage BLEU score: 27.53\nExact Match: 2.86%\nF1 Score: 45.05%\nScores of rag_best_chunk model :\nAverage BLEU score: 36.35\nExact Match: 8.41%\nF1 Score: 55.30%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Evaluating tuned model for the sampled example :","metadata":{}},{"cell_type":"code","source":"answer_top_chunk=rag_tuned_model.answer(sample[\"question\"].values[0])\nanswer_top_answer=rag_tuned_model.answer(sample[\"question\"].values[0],on_top_chunk=False)\nanswer_top_answer,answer_top_chunk,sample[\"answer\"].values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:05:29.921739Z","iopub.execute_input":"2025-05-24T07:05:29.922035Z","iopub.status.idle":"2025-05-24T07:05:33.781702Z","shell.execute_reply.started":"2025-05-24T07:05:29.922014Z","shell.execute_reply":"2025-05-24T07:05:33.780993Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('The responsibilities and requirements for the Software Architect position at the entertainment company include establishing relationship with customer technical teams and technical leads, communicating technical architectures to customers, focusing on technical benefits and competitive differentiation, assessing business opportunity and technical innovations, translating customer technical and business requirements into technical solutions, building relationships',\n 'The responsibilities and requirements for the Software Architect position at the entertainment company include the ability to interact and work collaboratively with all members of the organization, a bachelor’s degree in information technology, computer science, or related field, 3-5 years related experience, industry certifications and membership, excellent problem-',\n 'The responsibilities and requirements for the Software Architect position include developing and analyzing the design and architecture of complex software application systems, providing architectural and implementation oversight, analyzing and documenting existing systems, communicating technical issues clearly, writing and debugging complex problems in various software modules, managing test and acceptance activities, designing and building reusable modules, writing application code using latest C# and ASP.NET framework, assisting in building database structure for SQL Server, understanding cloud engineering, handling and prioritizing multiple tasks, demonstrating strong analytical and problem solving skills, having very good communication skills, having 10+ years of professional web development experience using C#, .NET, ASP.NET 3.5 – 4.0, MVC, and WCF, having 7+ year’s professional experience with SQL Server 2012 and up, having hands-on experience with HTML5, CSS3, Javascript, understanding of XML/Web services, having a Bachelor’s degree or equivalent in a relevant discipline, and having experience with agile software development, Test Driven Development (TDD), and Cloud IVR, Live Video Chat, Chat and texting web integration.')"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(\"Comparisons with dataset answer, on top_answer: \"+\nf\"\\nF1:{f1_score(answer_top_answer, sample['answer'].values[0]):.2f}\",\n      f\"BLEU:{bleu_score(answer_top_answer, sample['answer'].values[0]):.2f}\",\nf\"EM:{exact_match_score(answer_top_answer, sample['answer'].values[0]):.2f}\",\"\\non context chunk: \"+\nf\"\\nF1:{f1_score(answer_top_chunk, sample['answer'].values[0]):.2f}\",\n      f\"BLEU:{bleu_score(answer_top_chunk, sample['answer'].values[0]):.2f}\",\nf\"EM:{exact_match_score(answer_top_chunk, sample['answer'].values[0]):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T07:14:31.776873Z","iopub.execute_input":"2025-05-24T07:14:31.777520Z","iopub.status.idle":"2025-05-24T07:14:31.791328Z","shell.execute_reply.started":"2025-05-24T07:14:31.777499Z","shell.execute_reply":"2025-05-24T07:14:31.790506Z"}},"outputs":[{"name":"stdout","text":"Comparisons with dataset answer, on top_answer: \nF1:0.15 BLEU:0.01 EM:0.00 \non context chunk: \nF1:0.20 BLEU:0.02 EM:0.00\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## 5. Final Comparison of All Model Configurations\n\nThis table summarizes the performance of all major configurations evaluated throughout the project.\n\n| Model Configuration         | on_top_chunk | Training Type     | Exact Match (%) | F1 Score (%) | BLEU Score |\n|----------------------------|--------------|-------------------|-----------------|--------------|------------|\n| Zero-Shot                  | False           | Pretrained only   | 0.06            | 10.76         | 1.43       |\n| Zero-Shot      | True            | Pretrained only   | 0.06            | 17.51         | 2.71       |\n| Fine-Tuned     | False           | Supervised tuning   | 2.86           | 45.05         | 27.53       |\n| Fine-Tuned   | True           | Supervised tuning | 8.41           | 55.30         | 36.35       |","metadata":{}}]}